{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFtgk4YsYPudcC07Fu3YdI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6I5fDDAiSOt",
        "outputId": "00f39419-edcc-483d-ac90-52b023f07b6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dINV6n7iKtg"
      },
      "outputs": [],
      "source": [
        "# Ваш текст\n",
        "text = \"\"\"\n",
        "When forty winters shall besiege thy brow,\n",
        "And dig deep trenches in thy beauty's field,\n",
        "Thy youth's proud livery so gazed on now,\n",
        "Will be a totter'd weed of small worth held:\n",
        "Then being asked, where all thy beauty lies,\n",
        "Where all the treasure of thy lusty days;\n",
        "To say, within thine own deep sunken eyes,\n",
        "Were an all-eating shame, and thriftless praise.\n",
        "How much more praise deserv'd thy beauty's use,\n",
        "If thou couldst answer 'This fair child of mine\n",
        "Shall sum my count, and make my old excuse,'\n",
        "Proving his beauty by succession thine!\n",
        "This were to be new made when thou art old,\n",
        "And see thy blood warm when thou feel'st it cold.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Предобработка текста\n",
        "sentences = sent_tokenize(text)\n",
        "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
        "cleaned_sentences = [[re.sub(r'[^\\w\\s]', '', word) for word in sentence if word.isalnum()] for sentence in tokenized_sentences]\n",
        "print(len(cleaned_sentences))\n",
        "print(cleaned_sentences[0][:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jifYDD94iYEL",
        "outputId": "d21d6ac3-ba44-4faf-88cb-eb453af7663b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "['when', 'forty', 'winters']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание словаря слов\n",
        "word2index = {}\n",
        "for sentence in cleaned_sentences:\n",
        "    for word in sentence:\n",
        "        if word not in word2index:\n",
        "            word2index[word] = len(word2index)\n",
        "\n",
        "print(len(word2index))\n",
        "print(word2index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3tbYEaLic_i",
        "outputId": "2774b84d-e1dd-4968-fbf1-7034d4586772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83\n",
            "{'when': 0, 'forty': 1, 'winters': 2, 'shall': 3, 'besiege': 4, 'thy': 5, 'brow': 6, 'and': 7, 'dig': 8, 'deep': 9, 'trenches': 10, 'in': 11, 'beauty': 12, 'field': 13, 'youth': 14, 'proud': 15, 'livery': 16, 'so': 17, 'gazed': 18, 'on': 19, 'now': 20, 'will': 21, 'be': 22, 'a': 23, 'totter': 24, 'weed': 25, 'of': 26, 'small': 27, 'worth': 28, 'held': 29, 'then': 30, 'being': 31, 'asked': 32, 'where': 33, 'all': 34, 'lies': 35, 'the': 36, 'treasure': 37, 'lusty': 38, 'days': 39, 'to': 40, 'say': 41, 'within': 42, 'thine': 43, 'own': 44, 'sunken': 45, 'eyes': 46, 'were': 47, 'an': 48, 'shame': 49, 'thriftless': 50, 'praise': 51, 'how': 52, 'much': 53, 'more': 54, 'deserv': 55, 'use': 56, 'if': 57, 'thou': 58, 'couldst': 59, 'answer': 60, 'fair': 61, 'child': 62, 'mine': 63, 'sum': 64, 'my': 65, 'count': 66, 'make': 67, 'old': 68, 'excuse': 69, 'proving': 70, 'his': 71, 'by': 72, 'succession': 73, 'this': 74, 'new': 75, 'made': 76, 'art': 77, 'see': 78, 'blood': 79, 'warm': 80, 'it': 81, 'cold': 82}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Параметры эмбеддингов\n",
        "embedding_dim = 512\n",
        "vocab_size = len(word2index)\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Frz3I3ITigdC",
        "outputId": "a137f465-36b2-4ebf-938f-688f35cf2858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение модели и оптимизатора\n",
        "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "optimizer = optim.SGD(embedding.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "BD1-DIlXij1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Преобразование текста в индексы слов и обучение эмбеддингов\n",
        "for sentence in cleaned_sentences:\n",
        "    sentence_indices = [word2index[word] for word in sentence]\n",
        "    inputs = torch.tensor(sentence_indices, dtype=torch.long)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    embeddings = embedding(inputs)"
      ],
      "metadata": {
        "id": "UZkC_gU1imhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sentence)"
      ],
      "metadata": {
        "id": "FOqLCz-9df4V",
        "outputId": "8f7c757c-f476-41d3-b869-8c935bb14bc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu59gmz1dDyA",
        "outputId": "8d964e92-0f85-4e2c-9929-5e4dc2ba714e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([19, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Получение эмбеддинга слова 'beauty'\n",
        "word = 'beauty'\n",
        "word_index = word2index[word]\n",
        "word_embedding = embedding(torch.tensor(word_index, dtype=torch.long))\n",
        "\n",
        "print(\"Embedding shape:\", word_embedding.shape)\n",
        "print(\"Word embedding for 'beauty':\", word_embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0g4W17HirgI",
        "outputId": "c131081c-fcf3-44b5-f405-832adfe8a8c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding shape: torch.Size([512])\n",
            "Word embedding for 'beauty': tensor([-0.3590, -1.1928,  1.6611,  1.7691,  1.3573, -0.3558,  0.4064,  0.0842,\n",
            "         2.1095, -0.3887,  0.4658, -0.7139, -1.9074, -0.1974, -1.6055, -1.0716,\n",
            "         1.7210,  0.1064, -1.7098, -1.1973, -1.3233,  0.7135, -1.1613, -0.9669,\n",
            "         0.3900,  0.7677,  0.9488, -0.3492,  0.7302, -1.0765,  0.7387, -0.8672,\n",
            "         0.4349,  0.7074,  0.2048, -0.1203, -0.3244, -0.5152,  1.3766, -0.6108,\n",
            "         0.6751,  0.4109,  0.3840, -1.4749,  0.3168, -0.9714, -0.7062,  0.9085,\n",
            "        -2.1435, -1.0143, -0.7145, -1.4488,  1.5565, -0.2585,  0.3723,  1.7948,\n",
            "        -1.2921,  0.4260, -0.4980,  0.8809,  0.0657, -0.5571,  0.0134,  0.6140,\n",
            "        -2.6786, -0.6373,  0.7164, -0.4744,  1.9497,  1.4470,  0.1665,  0.4413,\n",
            "         1.1661,  0.3300, -1.1124, -1.2696, -0.7394, -0.9506,  0.6891,  0.2205,\n",
            "        -0.1828,  1.8397,  0.3128, -0.7749,  0.0542,  0.9884, -0.0557, -1.8347,\n",
            "        -0.4054, -1.4507, -1.2086, -0.2523, -0.9836,  1.8530,  0.2806, -1.4959,\n",
            "         0.9933,  1.2641,  1.4883, -0.2939, -0.3636, -0.5514, -0.0948,  0.9143,\n",
            "         2.1133, -0.4674,  1.4259,  1.7369, -0.4733,  0.3366,  0.6011,  0.5094,\n",
            "         0.6587,  0.2889, -1.1089, -1.5296,  0.8145,  0.9430, -1.1947, -0.0039,\n",
            "         0.6961, -0.9393,  1.0140, -2.5895,  0.7251, -0.1584,  0.3209, -1.2007,\n",
            "         0.0496, -1.8918,  0.0803,  0.1954,  1.2570, -0.0210, -1.4853,  1.3162,\n",
            "        -0.0280,  0.8921, -0.1380,  1.3356, -0.0634, -0.1284,  0.7855, -0.9420,\n",
            "         0.2337, -0.8543,  1.2292, -0.3748, -0.7445,  0.4850,  0.2728,  0.2205,\n",
            "        -0.3519, -1.0337,  0.5481, -2.0781, -0.6530,  1.3227,  0.8201, -2.1548,\n",
            "         0.3625, -0.6970,  2.2988, -0.9368,  2.3989, -0.3873, -1.0755,  0.4704,\n",
            "         0.3476,  0.4339,  0.5656,  0.4999,  1.5896,  0.6652,  0.1905,  0.2919,\n",
            "         0.8816,  0.1911,  1.0336,  0.9673,  0.3583,  0.5400, -0.7585,  0.2901,\n",
            "        -1.1992,  0.9741,  2.2148, -0.3524, -0.2437, -0.2891,  0.8885,  1.2142,\n",
            "         1.0607,  1.6841,  1.5134,  0.0268,  0.9734, -0.4987,  0.4617,  0.1608,\n",
            "        -0.6499,  0.8506,  0.8701, -0.0510, -0.2257,  0.0347,  1.7694,  0.6162,\n",
            "        -0.6335, -0.3837,  1.2335, -0.4379, -0.6952, -0.3777,  1.6797, -1.1193,\n",
            "         0.8554,  1.6763,  0.9495, -1.0713, -0.7218, -0.9848,  0.5449,  0.5955,\n",
            "         0.6154, -0.9367, -0.1166, -1.1080,  1.1711,  0.2284,  0.3304, -1.6377,\n",
            "         1.1597,  1.2327, -0.2128,  1.6310,  2.4510,  1.0197,  0.2656, -0.1494,\n",
            "        -0.0543,  0.7010,  1.0647,  0.1236, -0.5861, -1.2580, -2.4769, -1.0045,\n",
            "        -0.0764,  0.2845, -0.5442,  0.1450,  0.7706,  0.1372,  1.4347, -0.4514,\n",
            "        -0.2869, -1.4296,  0.7064,  0.0765, -0.1800, -1.3424, -0.4025, -0.2602,\n",
            "        -0.3367,  0.8119,  1.2921, -0.0647, -0.7650,  1.2124, -1.1671,  0.6045,\n",
            "         1.2108,  0.6101, -1.8658, -0.6231,  1.6434,  1.3355, -0.3417,  0.2101,\n",
            "         0.6589,  1.0217,  0.1568, -2.2029, -1.0887,  0.0027, -0.6048, -1.3630,\n",
            "        -0.0384,  1.3236, -0.3432,  0.9542, -0.5311, -0.4927, -0.4277, -0.4997,\n",
            "         0.4815,  0.8726, -0.1997, -0.1494,  0.7556, -1.3140,  0.5805, -0.8245,\n",
            "         0.0189, -0.4878, -0.6354, -0.3968, -0.4517,  0.1350, -0.6894, -0.3588,\n",
            "        -0.3706, -0.5480,  0.9797, -0.0066, -0.9001,  0.9946,  1.1922, -0.9543,\n",
            "        -1.7369, -2.5745, -1.4018, -0.8556, -0.5562,  1.2294, -2.0266, -0.9796,\n",
            "         0.2997, -1.2033,  1.2021,  0.2025, -0.8385, -1.0953,  0.2790, -0.5016,\n",
            "         1.2066, -0.4248,  0.1354,  0.3088, -0.5450, -0.5107,  0.1036,  0.3724,\n",
            "         0.3130,  0.6237,  0.1361, -0.7436,  0.3875,  0.9564,  0.3098, -0.5284,\n",
            "        -0.5037, -1.1755, -0.9833,  1.5337,  0.8104, -0.9969,  0.3638, -0.9374,\n",
            "        -1.4019,  0.3915,  2.2329, -0.8077, -0.3722,  0.8370,  0.8765, -0.9199,\n",
            "        -1.4147,  0.5603, -1.2892,  1.1377, -0.8056, -0.8499,  0.5641, -1.5690,\n",
            "        -0.0168, -1.2537, -0.3181, -0.1337, -0.6596, -0.1037,  0.8731,  2.2293,\n",
            "        -1.1093,  2.2344,  0.4379,  0.0690, -0.8861,  0.3181, -2.3109, -0.3258,\n",
            "         1.2479, -0.3449, -1.0360, -0.9414,  0.1493,  0.2414,  0.4633,  0.4905,\n",
            "         0.6497, -1.4107, -2.5983,  1.3576, -0.0112, -0.2278, -0.3091,  0.3180,\n",
            "        -0.7373,  1.1399, -0.2469,  0.3250, -1.2648,  0.6448,  0.1028, -1.8711,\n",
            "        -1.3006, -1.0737,  0.0952, -0.8620,  0.7392,  0.1054,  0.3525, -1.9274,\n",
            "         0.4136, -1.4280,  0.5323,  1.4154, -0.3194, -0.3230,  0.9611, -0.0595,\n",
            "        -0.8744,  0.0573,  0.7538,  0.2573, -2.2235,  1.0122, -1.8652,  0.0968,\n",
            "        -0.2014,  0.0234, -1.0343, -0.9094, -1.0990,  0.7256, -1.3240, -1.7666,\n",
            "         0.1659,  0.2473,  0.1340,  0.3276, -1.0052, -0.9874, -0.2082, -0.3262,\n",
            "         0.1291, -0.8661,  0.0567, -0.2913,  0.0060, -1.4871, -0.1938, -0.9216,\n",
            "        -0.6483, -1.1798,  0.3952,  0.0220, -0.5867, -0.1714,  0.0681, -0.4763,\n",
            "         1.7695,  0.1246,  2.1284, -0.6577, -2.1587, -1.3032,  0.7333,  1.0511,\n",
            "         0.5085,  1.0917, -0.6691, -1.2987, -1.8815,  1.8457,  0.6629,  0.7387,\n",
            "        -0.6019,  0.4340, -0.9454, -0.1296,  1.2007,  0.3869,  0.5464,  1.2114,\n",
            "        -1.3156,  0.7004,  0.2775, -0.0447, -1.5256, -0.0278,  0.0400, -0.3593,\n",
            "        -2.0660, -1.3872, -0.4016,  2.1223, -1.8640,  0.4205,  1.5721, -0.8403],\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lCgNGk3Qc8Lc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}